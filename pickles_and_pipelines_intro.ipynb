{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Pipelines and Pickles\n",
    "> How to use transformers with sklearn's `cross_val_score` and export a machine learning model from a jupyter notebook.\n",
    "\n",
    "<img src=\"https://www.polyeurope.com/site/images/home_slider/pig_animation.gif\">\n",
    "\n",
    "#### Motivations:\n",
    "\n",
    "> We have learned how to train a machine learning model, and *we have discussed why we should never fit on our testing data*, but this becomes more complicated when we are using multiple fold cross validation ie breaking data into multiple splits. The solution for this is either a lot of manual code, or a pipeline.\n",
    "\n",
    ">What if we wanted to deploy a model? **Currently,** our modeling process is broken up into a bunch of different code cells within a jupyter notebook, and there is no way for us to ask the model to make predictions on new data without opening the notebook, running the code to train the model, importing new data, and manually running code cells to make predictions. Google data scientists are not sitting at their computer running `shift + enter` for the thousands of data points they receive every second. So how to we use our models outside of a jupyter notebook? The solution to that is the `pickle` library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><u> Students will be able to </u></h3>\n",
    "\n",
    "- Understand why pipelines are useful for model evaluation.\n",
    "- Learn to construct a simple pipeline.\n",
    "- Save a model or a pipeline as a `.pkl` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:20:59.336387Z",
     "start_time": "2020-10-09T06:20:58.003814Z"
    }
   },
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Transformers\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Modeling Evaluation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Pipelines\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import pickle\n",
    "\n",
    "# Mock Data\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's review the modeling workflow we've seen so far...\n",
    "\n",
    "In the cell below, we load the breast cancer dataset into a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:20:59.378538Z",
     "start_time": "2020-10-09T06:20:59.338127Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data['data'], columns = data['feature_names'])\n",
    "df['target'] = data['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*This particular dataset is used mostly for demonstration purposes so there is no cleaning required.* ***Normally,*** *the next step would be for us to clean and format our data so it can then be modeled. Because the data is clean, we will skip this step.*\n",
    "\n",
    "Next, we split our data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:20:59.395540Z",
     "start_time": "2020-10-09T06:20:59.380849Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# All dataset without target variable\n",
    "features = df.drop('target', axis = 1)\n",
    "# Isolated target variable\n",
    "target = df.target\n",
    "\n",
    "# Create two sets of data. One for training a model \n",
    "# and one for predicting on unseen data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a set of data for training we can scale the data. There are many ways to scale data. Today we will use sklearn's `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:20:59.406322Z",
     "start_time": "2020-10-09T06:20:59.398604Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we instantiate a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:20:59.412118Z",
     "start_time": "2020-10-09T06:20:59.408798Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use cross validation to evaluate model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:20:59.489658Z",
     "start_time": "2020-10-09T06:20:59.414615Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98591549, 0.95070423, 0.98591549])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(model, X_train_scaled, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have done this, we would likely make some alterations to the data or fit other models and compare each model's performance. But let's say that we decide this is our final model. The next thing we would do is test the model on our testing data.\n",
    "\n",
    "To do this, we fit the model to all of our training data, and evaluate performance on the testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:20:59.510499Z",
     "start_time": "2020-10-09T06:20:59.492009Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(X_train_scaled, y_train)\n",
    "train_preds = model.predict(X_train_scaled)\n",
    "test_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:20:59.518979Z",
     "start_time": "2020-10-09T06:20:59.514169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9882629107981221\n",
      "Testing Accuracy:  0.42657342657342656\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy: ', accuracy_score(train_preds, y_train))\n",
    "print('Testing Accuracy: ', accuracy_score(test_preds, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What did we do wrong?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T01:15:45.189096Z",
     "start_time": "2020-10-09T01:15:45.185953Z"
    }
   },
   "source": [
    "- \n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***When we scale data, the transformer should only be fit on whatever data the model is trained on.***\n",
    "\n",
    "We can repeat the process above, leaving out `cross_val_score` and technically this would be correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:20:59.554642Z",
     "start_time": "2020-10-09T06:20:59.522017Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=2020)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All dataset without target variable\n",
    "features = df.drop('target', axis = 1)\n",
    "# Isolated target variable\n",
    "target = df.target\n",
    "\n",
    "# Create two sets of data. One for training a model \n",
    "# and one for predicting on unseen data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=2020)\n",
    "\n",
    "# Scale training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns = features.columns)\n",
    "\n",
    "# Fit model on training data\n",
    "model = LogisticRegression(random_state=2020)\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we want to use the model on testing data, *we have to transform the test data with the transformer that has been fit on the training data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:20:59.562499Z",
     "start_time": "2020-10-09T06:20:59.556989Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare how the model performs on the unscaled and scaled testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:20:59.572115Z",
     "start_time": "2020-10-09T06:20:59.564726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unscaled  0.42657342657342656\n",
      "Scaled  0.9790209790209791\n"
     ]
    }
   ],
   "source": [
    "print('Unscaled ', model.score(X_test, y_test))\n",
    "print('Scaled ', model.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:20:59.603359Z",
     "start_time": "2020-10-09T06:20:59.574274Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=2020)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(features)\n",
    "X = scaler.transform(features)\n",
    "model.fit(X, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**But, what if we wanted to use multiple fold cross validation.** If the correct way to scale data is to only fit the transformer on the training data, how do we use `cross_val_score`?\n",
    "\n",
    "Under the hood, `cross_val_score` is making splits of the data we feed into the function, training on one split and making predictions on the other. For this to work with transformers, we would need to stick a transformer into the middle of that process. \n",
    "\n",
    "We could choose not to use `cross_val_score` but that puts us at risk of training or testing our model on a bad sample of data. After all, when we only use a single train test split there is a possibility that our split of the data, by random chance, happened to result in an unusually high or unusually low accuracy score. We don't want that. We want to report the most representative score for our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:21:01.614650Z",
     "start_time": "2020-10-09T06:20:59.605445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_test_scores = []\n",
    "for i in range(100):\n",
    "    _xtrain, _xtest, _ytrain, _ytest = train_test_split(features, target, random_state=i)\n",
    "    _scaler = StandardScaler()\n",
    "    _xtrain = _scaler.fit_transform(_xtrain)\n",
    "    _xtest = _scaler.transform(_xtest)\n",
    "    _model = LogisticRegression(random_state=2020)\n",
    "    _model.fit(_xtrain, _ytrain)\n",
    "    _test_score = _model.score(_xtest, _ytest)\n",
    "    _test_scores.append(_test_score)\n",
    "\n",
    "plt.figure(figsize=(20,5))   \n",
    "plt.bar([x for x in range(len(_test_scores))], _test_scores)\n",
    "plt.title('Testing Scores');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T15:27:30.018508Z",
     "start_time": "2020-10-07T15:27:28.242980Z"
    },
    "code_folding": []
   },
   "source": [
    "<u>In summary we need to be able to do the following:</u>\n",
    "1. Access splits made by sklearn's `cross_val_score`\n",
    "2. Fit the desired Transformer on the training split\n",
    "3. Transform the training data\n",
    "4. Fit the desired model on the training data\n",
    "5. Transform the testing data with the fitted transformer <u>(Never fit on the testing data)</u>\n",
    "6. Use our fitted model to make predictions on the transformed testing data.\n",
    "\n",
    "<img src=\"images/cross_validation.gif\" width=1000>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T15:49:31.824064Z",
     "start_time": "2020-10-07T15:49:31.590736Z"
    }
   },
   "source": [
    "# Introducing sklearn's pipeline\n",
    "\n",
    "![](https://raw.githubusercontent.com/learn-co-students/pickles-and-pipelines-seattle-ds-012720/4817cebf95395b6f10ad882bf9daac528a0650dc/visuals/transformer.gif)\n",
    "\n",
    "\n",
    "With a pipeline, this code...\n",
    "\n",
    "```python\n",
    "transformer.fit(X_train)\n",
    "X_train_transformed = transformer.transform(X_train)\n",
    "X_test_transformed = transformer.transform(X_test)\n",
    "model.fit(X_train_transformed)\n",
    "model.score(X_test_transformed)\n",
    "```\n",
    "\n",
    "...instead, looks like this:\n",
    "\n",
    "```python\n",
    "pipeline.fit(X_train)\n",
    "pipeline.score(X_test)\n",
    "```\n",
    "\n",
    "#### Benefits of the Pipeline\n",
    "\n",
    "- **Convenience and encapsulation**\n",
    "    - You only have to call fit and predict once on your data to fit a whole sequence of estimators.\n",
    "- **Joint parameter selection**\n",
    "     - You can grid search over parameters of all estimators in the pipeline at once.\n",
    "- **Safety**\n",
    "    - Pipelines help avoid leaking statistics from your test data into the trained model in cross-validation, by ensuring that the same samples are used to train the transformers and predictors.\n",
    "\n",
    "Let's create a Pipeline objects to do the following:\n",
    "- Scale data using `StandardScaler`\n",
    "- Fit a Logistic Regression model\n",
    "- Score on the testing data\n",
    "\n",
    "Sklearn makes this process very simple with their `make_pipeline` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:21:01.622749Z",
     "start_time": "2020-10-09T06:21:01.616087Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('logisticregression', LogisticRegression(random_state=2020))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(StandardScaler(), LogisticRegression(random_state=2020))\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can feed the pipeline into sklearn's `cross_val_score`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:21:01.696538Z",
     "start_time": "2020-10-09T06:21:01.624389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97887324, 0.95070423, 0.98591549])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(pipeline, X_train, y_train, cv=3)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it! The nice thing about pipelines is that it allows us to create and easily access different modeling strategies! We can even feed pipelines into other pipelines!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:21:01.702633Z",
     "start_time": "2020-10-09T06:21:01.698502Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocessing = make_pipeline(MinMaxScaler(), \n",
    "                              StandardScaler())\n",
    "\n",
    "full_pipeline = make_pipeline(preprocessing, \n",
    "                              LogisticRegression(random_state=2020))                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:21:01.775853Z",
     "start_time": "2020-10-09T06:21:01.705178Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97887324, 0.95070423, 0.98591549])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(full_pipeline, X_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:21:01.799688Z",
     "start_time": "2020-10-09T06:21:01.777947Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('logisticregression', LogisticRegression(random_state=2020))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:21:01.811815Z",
     "start_time": "2020-10-09T06:21:01.802509Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9790209790209791"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickling!\n",
    "\n",
    "From the [documentation](https://docs.python.org/3/library/pickle.html):\n",
    "\n",
    ">The pickle module implements binary protocols for serializing and de-serializing a Python object structure. “Pickling” is the process whereby a Python object hierarchy is converted into a byte stream, and “unpickling” is the inverse operation, whereby a byte stream (from a binary file or bytes-like object) is converted back into an object hierarchy. Pickling (and unpickling) is alternatively known as “serialization”, “marshalling,” 1 or “flattening”; however, to avoid confusion, the terms used here are “pickling” and “unpickling”.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to save a machine learning model\n",
    "\n",
    "1. Use python's built in `open` function to open a new file and save the opened file to a variable\n",
    "    - This function receives:\n",
    "        1. The name of the file you would like to open\n",
    "        2. The mode in which you would like to open the file\n",
    "            - For pickle the mode is `'wb'` which stands for \"write binary\".\n",
    "            \n",
    "2. Use `pickle.dump()` \n",
    "    - Feed into this function the object you would like to save (in this case, our model) and the variable in which we have saved the opened file. \n",
    "    \n",
    "3. Close the opened file by calling `.close()` on the file object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:21:01.856810Z",
     "start_time": "2020-10-09T06:21:01.814295Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline.fit(features, target)\n",
    "\n",
    "file = open('models/final_pipeline.pkl', 'wb')\n",
    "pickle.dump(pipeline, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to load a saved machine learning model\n",
    "\n",
    "1. Use python's build in `open()` function to open the file and save the opened file to a variable.\n",
    "    - Two things must be fed into this function:\n",
    "        1. The path to the file\n",
    "        2. The mode in which you would like to open the file. \n",
    "            - In this case, we will want to use `'rb'` which stands for \"read binary\".\n",
    "            \n",
    "2. Feed the opened file to `pickle.load()` to load in the model and save the loaded object to a variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:21:01.862919Z",
     "start_time": "2020-10-09T06:21:01.859199Z"
    }
   },
   "outputs": [],
   "source": [
    "file = open('models/final_pipeline.pkl', 'rb')\n",
    "saved_model = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:21:01.873307Z",
     "start_time": "2020-10-09T06:21:01.865312Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('logisticregression', LogisticRegression(random_state=2020))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlearn",
   "language": "python",
   "name": "mlearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
